{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Generate\tper\tbase\tcall\tdistribution\tof\tquality\tscores\tfor\tread1,\tread2,\tindex1,\tand\tindex2\n",
    "\n",
    "### a. Turn\tin\tthe\t8 histograms.\n",
    "\n",
    "All plots are in the plots html file.\n",
    "\n",
    "### b. What\tis\ta\tgood\tquality\tscore\tcutoff for\tindex\treads\tand\tpairs\tto\tutilize\tfor\tsample identification\tand\tdownstream\tanalysis,\trespectively?\n",
    "\n",
    "For index reads I proposed a cutoff quality score of 30. For both data sets, exluding 38, 37 is the highest quality score observed throughout all the reads. Beyond that the quality seems to slowly taper down linearly, the lower the score the fewer the reads belonging to that group. There are a few exceptions, such as 35 having fewer reads than 34, however the categories are all fairly close together until 30. In both data sets the data begins to vary drastically between a quality score of 24 and 29. With a quality score of 30 we still retain over 90% of our data and eliminate some of the unwanted variance due to errors.\n",
    "\n",
    "For sequence reads I would select between a quality score of 35 or 30 depending on how much specificity I was looking for. For higher quality data I would use a cutoff score of 35, as that contains the 6 largest QS bins for both our FW and RV reads and also comprises over 90% of the data. However if looking for rare variants, or aligning to a good reference then I also thin ka QS cutoff of 30 may be acceptable. Likewise it would include the top 11 bin categories and add a 30-50~ million more reads. Ultimately it depends on how much data you have generated, though when in doubt it is better to sacrifice quantity for quality.\n",
    "\n",
    "### c. How\tmany\tindexes\thave\tUndetermined\t(N)\tbase\tcalls? (Utilize\tyour\tcommand\tline\ttool\tknowledge.\tSummit\tthe\tcommand\tyou\tused.\tCHALLENGE:\tuse\ta\tone line\tcommand)\n",
    "\n",
    "Total Reads: 363246735\n",
    "\n",
    "For the first index I used a simple cat + awk for sequence lines plus 'N': 3976613, which is just over 1%\n",
    "\n",
    "```\n",
    "cat 1294_S1_L008_R2_001.fastq | awk 'NR%4==2' | grep \"N\" | wc -l\n",
    "```\n",
    "\n",
    "Same for the second index: 3328051, which is just under 1%\n",
    "\n",
    "```\n",
    "cat 1294_S1_L008_R3_001.fastq | awk 'NR%4==2' | grep \"N\" | wc -l\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write\ta\tprogram\tto\tde-multiplex\tthe\tsamples\tand\tdocument\tindex\tswapping and number\tof\treads\tretained\tper\tsample.\n",
    "\n",
    "### a. How\tmany reads\tare\tretained\tfor\teach\texpected\tindex\tpair?\tWhat\tis\tthe\tpercentage?\n",
    "\n",
    "See table on HTML for all numbers/percents.\n",
    "\n",
    "In total we had over 93.42% of our reads kept after our quality cutoff of 30, and of those, 94.9% were proper index pairs. However of the 24 indexes the top 3 indexes by count make up over 45% of the sequences. This means we had a large amount of preferential sequencing or amplification, specially for our TACCGGAT index which represented 23.02% of our sample.\n",
    "\n",
    "### b. How\tmany\treads\tare\tindicative\tof\tindex\tswapping?\n",
    "\n",
    "Total number of reads  kept: 339335851\n",
    "From our retained reads, we observed index swapping without and undefined character and being a perfect match for our original indexes, on 606628 reads. This amounts to about 0.18% of our quality trimmed indexes.\n",
    "\n",
    "However if you combine that with index pairs with at least one N (.99%) and index pairs that don't match our original indexes (3.93%, likely sequence errors) then in total we observed about 5% unexpected indexing results in our quality trimmed indexes.\n",
    "\n",
    "### c. Create\ta\tdistribution\tof\tswapped\tindexes.\tWhat\tdoes\tthis\thistogram\ttell\tyou/what\tis\tyour\tinterpretation\tof\tthis\tdata?\n",
    "\n",
    "In our case it is clear that index swapping is an event that is not entirely random. We observed a clear favoring of index TATGGCAC and TGTTCCGT being preferentially swapped with both combinations of those indexes representing over 25% of the 522 observed swaps. This is surprising as these samples' abundance on our proper index matches were only 5th and 8th, representing 4.76% and 3.36% of indexes, hardly enough to warrant over 25% of swaps. There is clearly another relationship at play. This is further evidenced by the fact that both of these indexes are not present in any other combination in the rest of the top 10 observed swaps.\n",
    "\n",
    "According to our index file, these two indexes belong samples 17 & 19, groups 3E and 3F both the fox treatment. This may have something to do with the preverential swap. However the most likely explanation which is supported by the research is that these samples had a higher number of index library added to the sample which did not entirely bind, and that was then not accurately size selected.\n",
    "\n",
    "In colusion there seem to be a select few (in this case two) indexes that showed a large degree of index swapping. Though they equate to the same treatment and subsequent samples, this is likely a coincidence and the real reason for this over-representation was a large amount of leftover index library leftover during sample preparation.\n",
    "\n",
    "The table of all index swaps observed sorted by abundance is located at the end of the html file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Cell Following this one includes the code to generate all the quality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lane Hop Assignment\n",
    "\n",
    "# R1 = Forward read file\n",
    "# R2 = First index\n",
    "# R3 = Reverse index\n",
    "# R4 = Reverse read\n",
    "\n",
    "#To convert phred scores to numbers\n",
    "def convert_phred(letter):\n",
    "    \"\"\"Converts a single character into a phred score\"\"\"\n",
    "    QScore = ord(letter) - 33\n",
    "    return QScore\n",
    "\n",
    "#First we get all the quality scores for both reads and bp positions\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "#First we create an array that will hold all the scores for each bp position of the read, and define it all as a function\n",
    "#Additionally it will also create a dictionary with the QS of each read rounded out\n",
    "def Get_QS(file):\n",
    "    myfile = open(file)\n",
    "    readQS = {}\n",
    "    mean_scores = []\n",
    "    NR = 0\n",
    "    for lines in myfile:\n",
    "        lines=lines.rstrip()\n",
    "        current_read = 0\n",
    "        if NR == 1:\n",
    "            for i in range(len(lines)):\n",
    "                mean_scores.append(0.0)\n",
    "        NR = NR + 1\n",
    "        #This first line will simply add the score for the first time through, makes it easier to divide by two further on\n",
    "        if NR == 4:\n",
    "            for i in range((len(lines))):\n",
    "                #In this part we are using current_read to find the QS for the whole read, and mean_scores for the bp QS\n",
    "                current_read = current_read + convert_phred(lines[i])\n",
    "                mean_scores[i] = mean_scores[i] + convert_phred(lines[i])\n",
    "            #Here we are rounding our average read QS and then placing it in our dictionary\n",
    "            current_read = round(current_read/((len(lines))))\n",
    "            if current_read in readQS:\n",
    "                readQS[current_read] +=1\n",
    "            else:\n",
    "                readQS[current_read] = 1\n",
    "        elif NR%4 == 0: #This selects the quality score lines, this bottom is a repeat of the top except for =! first quality line\n",
    "            for i in range((len(lines))):\n",
    "                current_read = current_read + convert_phred(lines[i])\n",
    "                mean_scores[i] = mean_scores[i] + convert_phred(lines[i])\n",
    "            current_read = round(current_read/(len(lines)))\n",
    "            if current_read in readQS:\n",
    "                readQS[current_read] +=1\n",
    "            else:\n",
    "                readQS[current_read] = 1\n",
    "    for each in range(len(mean_scores)):\n",
    "        mean_scores[each]=round((mean_scores[each]/(NR/4)),2)\n",
    "    myfile.close()\n",
    "    print(\"NR IS\",NR)\n",
    "    return [readQS,mean_scores] #Output is a list, with the first item being our dictionary of QS per read, and the second\n",
    "                                #item being a list of our bp position QS\n",
    "\n",
    "#Run out function on all 3 files to get both read QS and bp QS\n",
    "R1QS = Get_QS(\"Undetermined_S0_R1_001_trunc.fastq\")\n",
    "R1readQS = R1QS[0]\n",
    "R1bpQS = R1QS[1]\n",
    "\n",
    "R2QS = Get_QS(\"Undetermined_S0_R2_001_trunc.fastq\")\n",
    "R2readQS = R2QS[0]\n",
    "R2bpQS = R2QS[1]\n",
    "\n",
    "R3QS = Get_QS(\"Undetermined_S0_R3_001_trunc.fastq\")\n",
    "R3readQS = R3QS[0]\n",
    "R3bpQS = R3QS[1]\n",
    "\n",
    "R4QS = Get_QS(\"Undetermined_S0_R4_001_trunc.fastq\")\n",
    "R4readQS = R4QS[0]\n",
    "R4bpQS = R4QS[1]\n",
    "\n",
    "#Get a final bp average QS for R1 and R4, this is the sequencing QS average per BP\n",
    "FinalBPQS=[]\n",
    "for i in range(101):\n",
    "    FinalBPQS.append(0.0)\n",
    "for i in range((len(R1bpQS))):\n",
    "    FinalBPQS[i]=(R1bpQS[i]+R4bpQS[i])/2\n",
    "    \n",
    "#In this part we will combine all 4 dictionaries to a per read QS total\n",
    "FinalreadQS={}\n",
    "#Dic1\n",
    "for key, value in R1readQS.items():\n",
    "    if key in FinalreadQS:\n",
    "        FinalreadQS[key] +=value\n",
    "    else:\n",
    "        FinalreadQS[key] = value\n",
    "#Dic2\n",
    "for key, value in R2readQS.items():\n",
    "    if key in FinalreadQS:\n",
    "        FinalreadQS[key] +=value\n",
    "    else:\n",
    "        FinalreadQS[key] = value\n",
    "#Dic3\n",
    "for key, value in R3readQS.items():\n",
    "    if key in FinalreadQS:\n",
    "        FinalreadQS[key] +=value\n",
    "    else:\n",
    "        FinalreadQS[key] = value\n",
    "#Dic4        \n",
    "for key, value in R4readQS.items():\n",
    "    if key in FinalreadQS:\n",
    "        FinalreadQS[key] +=value\n",
    "    else:\n",
    "        FinalreadQS[key] = value\n",
    "\n",
    "###############################################################################\n",
    "#Write out our results to separate files\n",
    "\n",
    "#First one file for each original base pair QS\n",
    "with open('R1readQS.txt', 'w') as f:\n",
    "     f.write(str(R1readQS))\n",
    "with open('R2readQS.txt', 'w') as f:\n",
    "     f.write(str(R2readQS))\n",
    "with open('R3readQS.txt', 'w') as f:\n",
    "     f.write(str(R3readQS))\n",
    "with open('R4readQS.txt', 'w') as f:\n",
    "     f.write(str(R4readQS))\n",
    "\n",
    "# #Next one file for each original read QS\n",
    "with open('R1bpQS.txt', 'w') as f:\n",
    "     f.write(str(R1bpQS))\n",
    "with open('R2bpQS.txt', 'w') as f:\n",
    "     f.write(str(R2bpQS))\n",
    "with open('R3bpQS.txt', 'w') as f:\n",
    "     f.write(str(R3bpQS))\n",
    "with open('R4bpQS.txt', 'w') as f:\n",
    "     f.write(str(R4bpQS))\n",
    "\n",
    "#Finally a file for the combined read QS and bp QS\n",
    "with open('FinalReadQS.txt', 'w') as f:\n",
    "     f.write(str(FinalreadQS))\n",
    "with open('FinalBPQS.txt', 'w') as f:\n",
    "     f.write(str(FinalBPQS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cell below includes the code to generate the preliminary Index Hop Data, no mean quality score used (for curiosity while the other ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index Hopping Problem\n",
    "\n",
    "#Write a function to get the complement of the reverse index\n",
    "def Complement(index):\n",
    "    #First we make our index into a list so we can modify it\n",
    "    index = list(index)\n",
    "    for each in range(len(index)):\n",
    "        #First we replace all the nucleotides to complements\n",
    "        if index[each]=='N':\n",
    "            index[each]='N'\n",
    "        elif index[each]=='A':\n",
    "            index[each]='T'\n",
    "        elif index[each]=='T':\n",
    "            index[each]='A'\n",
    "        elif index[each]=='C':\n",
    "            index[each]='G'\n",
    "        elif index[each]=='G':\n",
    "            index[each]='C'\n",
    "    #Now we return it to a string\n",
    "    index=\"\".join(index)\n",
    "    #Then we inverse the order\n",
    "    index=index[::-1]\n",
    "    return index\n",
    "\n",
    "#Establish our list of known indexes. THE FIRST IS THE REAL FILE, SECOND IS FOR TEST FILE, AND REVERSE COMPLEMENT\n",
    "Indexes = ['GTAGCGTA', 'CGATCGAT', 'GATCAAGG', 'AACAGCGA', 'TAGCCATG', 'CGGTAATC', 'CTCTGGAT', 'TACCGGAT', 'CTAGCTCA', 'CACTTCAC', 'GCTACTCT', 'ACGATCAG', 'TATGGCAC', 'TGTTCCGT', 'GTCCTAAG', 'TCGACAAG', 'TCTTCGAC', 'ATCATGCG', 'ATCGTGGT', 'TCGAGAGT', 'TCGGATTC', 'GATCTTGC', 'AGAGTCCA', 'AGGATAGC']\n",
    "#Indexes = ['ATTGCATA', 'TGGCGTAT', 'GCGATAGC', 'CGAATGCG', 'TTGTCAGG', 'AACGCACC', 'CCGGTAAC', 'GGCGATCA', 'GAAATCTA', 'TCAGTAGA', 'AGGTCCGA', 'CATGTATC']\n",
    "\n",
    "#Make our dictionary that will hold our index pairs\n",
    "IndexPairs = {} #This dictionary holds our expected indexes\n",
    "IndexPairsList = 0 #Keeps count\n",
    "\n",
    "IndexHop = {} #This dictionary holds our index hops\n",
    "IndexHopList = 0 #Keeps count\n",
    "\n",
    "IndexWithN = 0 #This is a count of any index pairs found with an N\n",
    "\n",
    "NonIndexPairs = {} #This dictionary holds any non 'N' index pairs not part of our index library\n",
    "NonIndexPairsList = 0 #Keeps count\n",
    "\n",
    "Total_Reads=0 #Keeps count of total number of reads\n",
    "\n",
    "#Open both the index files simultaneously and go line by line comparing each\n",
    "#with open(\"Undetermined_S0_R2_001_trunc.fastq\") as textfile1, open(\"Undetermined_S0_R3_001_trunc.fastq\") as textfile2:\n",
    "with open(\"R2.fastq\") as textfile1, open(\"R3.fastq\") as textfile2: \n",
    "    NR=0\n",
    "    for x, y in zip(textfile1, textfile2):\n",
    "        NR+=1\n",
    "        if NR%4 == 2: #Looks at the sequence lines\n",
    "            Total_Reads+=1\n",
    "            x = x.strip() #Removes the \\n\n",
    "            y = y.strip()\n",
    "            y = Complement(y) #Gets the reverse complement of the index\n",
    "            #print(x)\n",
    "            #print(y)\n",
    "            #Checks to see if both indexes from our list of known\n",
    "            if x in Indexes and y in Indexes:\n",
    "                if x == y:\n",
    "                    IndexPairsList+=1\n",
    "                    if str(x+\" \"+y) in IndexPairs:\n",
    "                        IndexPairs[x+\" \"+y]+=1\n",
    "                    else:\n",
    "                        IndexPairs[x+\" \"+y]=1\n",
    "                elif x != y:\n",
    "                    IndexHopList+=1\n",
    "                    if str(x+\" \"+y) in IndexHop:\n",
    "                        IndexHop[x+\" \"+y]+=1\n",
    "                    else:\n",
    "                        IndexHop[x+\" \"+y]=1\n",
    "            #Checks to see if either of the indexes have an undefined 'N' character\n",
    "            elif 'N' in x or 'N' in y:\n",
    "                IndexWithN+=1\n",
    "            #Assumes all remaining indexes are non undefined non library pairs, likely sequence errors\n",
    "            else:\n",
    "                #This should be non N characters but not from our index list\n",
    "                NonIndexPairsList+=1\n",
    "                if str(x+\" \"+y) in NonIndexPairs:\n",
    "                    NonIndexPairs[x+\" \"+y]+=1\n",
    "                else:\n",
    "                    NonIndexPairs[x+\" \"+y]=1\n",
    "\n",
    "#Get some stats on the run\n",
    "print(\"The number of Proper Index Pairs observed are:\",IndexPairsList,\"Percent of total reads:\",round((IndexPairsList/Total_Reads),4)*100)\n",
    "print(\"The number of Index Hopping Events observed are:\",IndexHopList,\"Percent of total reads:\",round((IndexHopList/Total_Reads),4)*100)\n",
    "print(\"The number of Index pairs with at least one 'N' are:\", IndexWithN,\"Percent of total reads:\",round((IndexWithN/Total_Reads),4)*100)\n",
    "print(\"The number of Non Proper Non 'N' Indexes observed is:\",NonIndexPairsList,\"Percent of total reads:\",round((NonIndexPairsList/Total_Reads),4)*100)\n",
    "print(\"The total number of reads examined was\",Total_Reads)\n",
    "\n",
    "with open('ProperIndexPairsDic.txt', 'w') as f:\n",
    "     f.write(str(IndexPairs))\n",
    "with open('IndexHoppingDic.txt', 'w') as f:\n",
    "     f.write(str(IndexHop))\n",
    "with open('NonIndexNonUndefinedPairs.txt', 'w') as f:\n",
    "     f.write(str(NonIndexPairs))\n",
    "\n",
    "#print(IndexPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code below was used to generate the quality score filtered index swaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index Hopping Problem\n",
    "\n",
    "#Write a function to get the complement of the reverse index\n",
    "def Complement(index):\n",
    "    #First we make our index into a list so we can modify it\n",
    "    index = list(index)\n",
    "    for each in range(len(index)):\n",
    "        #First we replace all the nucleotides to complements\n",
    "        if index[each]=='N':\n",
    "            index[each]='N'\n",
    "        elif index[each]=='A':\n",
    "            index[each]='T'\n",
    "        elif index[each]=='T':\n",
    "            index[each]='A'\n",
    "        elif index[each]=='C':\n",
    "            index[each]='G'\n",
    "        elif index[each]=='G':\n",
    "            index[each]='C'\n",
    "    #Now we return it to a string\n",
    "    index=\"\".join(index)\n",
    "    #Then we inverse the order\n",
    "    index=index[::-1]\n",
    "    return index\n",
    "\n",
    "#To convert phred scores to numbers\n",
    "def convert_phred(letter):\n",
    "    \"\"\"Converts a single character into a phred score\"\"\"\n",
    "    QScore = ord(letter) - 33\n",
    "    return QScore\n",
    "\n",
    "#Establish our list of known indexes. THE FIRST IS THE REAL FILE, SECOND IS FOR TEST FILE, AND REVERSE COMPLEMENT\n",
    "Indexes = ['GTAGCGTA', 'CGATCGAT', 'GATCAAGG', 'AACAGCGA', 'TAGCCATG', 'CGGTAATC', 'CTCTGGAT', 'TACCGGAT', 'CTAGCTCA', 'CACTTCAC', 'GCTACTCT', 'ACGATCAG', 'TATGGCAC', 'TGTTCCGT', 'GTCCTAAG', 'TCGACAAG', 'TCTTCGAC', 'ATCATGCG', 'ATCGTGGT', 'TCGAGAGT', 'TCGGATTC', 'GATCTTGC', 'AGAGTCCA', 'AGGATAGC']\n",
    "#Indexes = ['ATTGCATA', 'TGGCGTAT', 'GCGATAGC', 'CGAATGCG', 'TTGTCAGG', 'AACGCACC', 'CCGGTAAC', 'GGCGATCA', 'GAAATCTA', 'TCAGTAGA', 'AGGTCCGA', 'CATGTATC']\n",
    "\n",
    "#Make our dictionary that will hold our index pairs\n",
    "IndexPairs = {} #This dictionary holds our expected indexes\n",
    "IndexPairsList = 0 #Keeps count\n",
    "\n",
    "IndexHop = {} #This dictionary holds our index hops\n",
    "IndexHopList = 0 #Keeps count\n",
    "\n",
    "IndexWithN = 0 #This is a count of any index pairs found with an N\n",
    "\n",
    "NonIndexPairs = {} #This dictionary holds any non 'N' index pairs not part of our index library\n",
    "NonIndexPairsList = 0 #Keeps count\n",
    "\n",
    "Total_Reads=0 #Keeps count of total number of reads\n",
    "Kept_reads=0 #Keeps track of all kept reads\n",
    "\n",
    "#Open both the index files simultaneously and go line by line comparing each\n",
    "#with open(\"Undetermined_S0_R2_001_trunc.fastq\") as textfile1, open(\"Undetermined_S0_R3_001_trunc.fastq\") as textfile2:\n",
    "with open(\"R2.fastq\") as textfile1, open(\"R3.fastq\") as textfile2: \n",
    "    NR=0\n",
    "    for x, y in zip(textfile1, textfile2):\n",
    "        NR+=1\n",
    "        if NR%4 == 0: #Looks at the quality scores\n",
    "            #This first part will look at the quality scores and see if they are worth retaining\n",
    "            current_read_FW = 0\n",
    "            current_read_RV = 0\n",
    "            x=x.strip()\n",
    "            y=y.strip()\n",
    "            #This loop adds up all the quality scores of the current line\n",
    "            for i in range((len(x))):\n",
    "                current_read_FW = current_read_FW + convert_phred(x[i])\n",
    "                current_read_RV = current_read_RV + convert_phred(y[i])\n",
    "            #Once we have all the quality scores we get the mean by dividing by the sequence length\n",
    "            current_read_FW = current_read_FW/((len(x)))\n",
    "            current_read_RV = current_read_RV/((len(y)))\n",
    "            finalQS = (current_read_FW+current_read_RV)/2\n",
    "            #The following line will retain the index pair if the QS is above or equal to 30, if so it will retain in\n",
    "            if finalQS >= 30:\n",
    "                Kept_reads+=1\n",
    "                #Checks to see if both indexes from our list of known\n",
    "                if FW in Indexes and RV in Indexes:\n",
    "                    #If they are equal, it's a proper match\n",
    "                    if FW == RV:\n",
    "                        IndexPairsList+=1\n",
    "                        if str(FW+\"_\"+RV) in IndexPairs:\n",
    "                            IndexPairs[FW+\"_\"+RV]+=1\n",
    "                        else:\n",
    "                            IndexPairs[FW+\"_\"+RV]=1\n",
    "                    #If not equal, but part of index list, then likely index hopping\n",
    "                    elif FW != RV:\n",
    "                        IndexHopList+=1\n",
    "                        if str(FW+\"_\"+RV) in IndexHop:\n",
    "                            IndexHop[FW+\"_\"+RV]+=1\n",
    "                        else:\n",
    "                            IndexHop[FW+\"_\"+RV]=1\n",
    "                #Checks to see if either of the indexes have an undefined 'N' character\n",
    "                elif 'N' in FW or 'N' in RV:\n",
    "                    IndexWithN+=1\n",
    "                #Assumes all remaining indexes are non undefined non library pairs, likely sequence errors\n",
    "                else:\n",
    "                    #This should be non N characters but not from our index list\n",
    "                    NonIndexPairsList+=1\n",
    "                    if str(FW+\"_\"+RV) in NonIndexPairs:\n",
    "                        NonIndexPairs[FW+\"_\"+RV]+=1\n",
    "                    else:\n",
    "                        NonIndexPairs[FW+\"_\"+RV]=1\n",
    "        if NR%4 == 2: #Looks at the sequence lines\n",
    "            Total_Reads+=1            \n",
    "            FW = x.strip() #Removes the \\n\n",
    "            RV = y.strip()\n",
    "            RV = Complement(RV) #Gets the reverse complement of the index\n",
    "            \n",
    "#Get some stats on the run\n",
    "print(\"The number of Proper Index Pairs observed are:\",IndexPairsList,\"Percent of total kept reads:\",round((IndexPairsList/Kept_reads)*100,2))\n",
    "print(\"The number of Index Hopping Events observed are:\",IndexHopList,\"Percent of total kept reads:\",round((IndexHopList/Kept_reads)*100,2))\n",
    "print(\"The number of Index pairs with at least one 'N' are:\", IndexWithN,\"Percent of total kept reads:\",round((IndexWithN/Kept_reads)*100,2))\n",
    "print(\"The number of Non Proper Non 'N' Indexes observed is:\",NonIndexPairsList,\"Percent of total kept reads:\",round((NonIndexPairsList/Kept_reads)*100,2))\n",
    "print(\"The total number of reads kept was \",Kept_reads,\"Percent of reads kept:\",round((Kept_reads/Total_Reads)*100,2))\n",
    "print(\"The total number of reads examined was\",Total_Reads)\n",
    "\n",
    "#Write out our output files\n",
    "with open('ProperIndexPairsDic.txt', 'w') as f:\n",
    "     f.write(str(IndexPairs))\n",
    "with open('IndexHoppingDic.txt', 'w') as f:\n",
    "     f.write(str(IndexHop))\n",
    "with open('NonIndexNonUndefinedPairs.txt', 'w') as f:\n",
    "     f.write(str(NonIndexPairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bash code for post data clean up\n",
    "\n",
    "In order to fix the dictionary outputs into a nice colon deliniated list for R, the following bash command is used:\n",
    "```\n",
    "cat R2readQS.txt | sed 's/{//' | sed 's/}//' | tr -d \\'\\\" | tr ',' '\\n' | sed 's/://' | sed -e '$a\\' > myfile\n",
    "```\n",
    "In order to fix the list files with the bp QS scores, the following bash command was used:\n",
    "```\n",
    "cat R3bpQS.txt | tr '[' '_' | tr ']' '_' | sed 's/_//g' | sed 's/,//g' | sed 's/ /\\n/g' | sed -e '$a\\'\n",
    "```\n",
    "\n",
    "To take a look at the large dictionary files printer on unix the following command was used:\n",
    "```\n",
    "cat NonIndexNonUndefinedPairs.txt | sed 's/{//' | sed 's/}//' | tr -d \\'\\\" | tr ',' '\\n' | sort -t':' -rnk2 | head\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
